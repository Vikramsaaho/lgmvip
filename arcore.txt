<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
	package="com.example.arsnapchat">

	<uses-feature
		android:name="android.hardware.camera"
		android:required="true" />

	<uses-permission android:name="android.permission.CAMERA" />
	<uses-permission android:name="android.permission.INTERNET" />

	<uses-feature
		android:name="android.hardware.camera.ar"
		android:required="true" />
	<uses-feature android:name="android.hardware.camera.autofocus" />
	
	<uses-feature
		android:glEsVersion="0x00020000"
		android:required="true" />

	<application
		android:allowBackup="true"
		android:icon="@mipmap/ic_launcher"
		android:label="@string/app_name"
		android:roundIcon="@mipmap/ic_launcher_round"
		android:supportsRtl="true"
		android:theme="@style/AppTheme">
		<meta-data
			android:name="com.google.ar.core"
			android:value="required" />
		<activity android:name=".MainActivity">
			<intent-filter>
				<action android:name="android.intent.action.MAIN" />

				<category android:name="android.intent.category.LAUNCHER" />
			</intent-filter>
		</activity>
	</application>

</manifest>
<?xml version="1.0" encoding="utf-8"?>
<androidx.constraintlayout.widget.ConstraintLayout
	xmlns:android="http://schemas.android.com/apk/res/android"
	xmlns:tools="http://schemas.android.com/tools"
	android:layout_width="match_parent"
	android:layout_height="match_parent"
	tools:context=".MainActivity">

	<fragment
		android:id="@+id/arFragment"
		android:name="com.example.arsnapchat.CustomArFragment"
		android:layout_width="match_parent"
		android:layout_height="match_parent" />

</androidx.constraintlayout.widget.ConstraintLayout>
import android.os.Bundle;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.FrameLayout;
import androidx.annotation.Nullable;
import com.google.ar.core.Config;
import com.google.ar.core.Session;
import com.google.ar.sceneform.ux.ArFragment;
import java.util.EnumSet;
import java.util.Set;

public class CustomArFragment extends ArFragment {
	@Override
	protected Config getSessionConfiguration(Session session) {
		Config config = new Config(session);

		// Configure 3D Face Mesh
		config.setAugmentedFaceMode(Config.AugmentedFaceMode.MESH3D);
		this.getArSceneView().setupSession(session);
		return config;
	}

	@Override
	protected Set<Session.Feature> getSessionFeatures() {
		// Configure Front Camera
		return EnumSet.of(Session.Feature.FRONT_CAMERA);
	}

	// Override to turn off planeDiscoveryController.
	// Plane traceable are not supported with the front camera.
	@Override
	public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
		FrameLayout frameLayout = (FrameLayout) super.onCreateView(inflater, container, savedInstanceState);
		getPlaneDiscoveryController().hide();
		getPlaneDiscoveryController().setInstructionView(null);
		return frameLayout;
	}
}
import android.os.Bundle;
import android.widget.Toast;
import androidx.appcompat.app.AppCompatActivity;
import com.google.ar.core.AugmentedFace;
import com.google.ar.core.Frame;
import com.google.ar.core.TrackingState;
import com.google.ar.sceneform.rendering.ModelRenderable;
import com.google.ar.sceneform.rendering.Renderable;
import com.google.ar.sceneform.rendering.Texture;
import com.google.ar.sceneform.ux.AugmentedFaceNode;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

public class MainActivity extends AppCompatActivity {
	private ModelRenderable modelRenderable;
	private Texture texture;
	private boolean isAdded = false;
	private final HashMap<AugmentedFace, AugmentedFaceNode> faceNodeMap = new HashMap<>();

	@Override
	protected void onCreate(Bundle savedInstanceState) {
		super.onCreate(savedInstanceState);
		setContentView(R.layout.activity_main);

		CustomArFragment customArFragment = (CustomArFragment) getSupportFragmentManager().findFragmentById(R.id.arFragment);

		// Use ModelRenderable.Builder to load the *.sfb
		// models at runtime.
		// Load the face regions renderable.
		// To ensure that the asset doesn't cast or receive
		// shadows in the scene, ensure that setShadowCaster
		// and setShadowReceiver are both set to false.
		ModelRenderable.builder()
				.setSource(this, R.raw.fox_face)
				.build()
				.thenAccept(rendarable -> {
					this.modelRenderable = rendarable;
					this.modelRenderable.setShadowCaster(false);
					this.modelRenderable.setShadowReceiver(false);

				})
				.exceptionally(throwable -> {
					Toast.makeText(this, "error loading model", Toast.LENGTH_SHORT).show();
					return null;
				});

		// Load the face mesh texture.(2D texture on face)
		// Save the texture(.png file) in drawable folder.
		Texture.builder()
				.setSource(this, R.drawable.fox_face_mesh_texture)
				.build()
				.thenAccept(textureModel -> this.texture = textureModel)
				.exceptionally(throwable -> {
					Toast.makeText(this, "cannot load texture", Toast.LENGTH_SHORT).show();
					return null;
				});

		assert customArFragment != null;

		// This is important to make sure that the camera
		// stream renders first so that the face mesh
		// occlusion works correctly.
		customArFragment.getArSceneView().setCameraStreamRenderPriority(Renderable.RENDER_PRIORITY_FIRST);
		customArFragment.getArSceneView().getScene().addOnUpdateListener(frameTime -> {
			if (modelRenderable == null || texture == null) {
				return;
			}
			Frame frame = customArFragment.getArSceneView().getArFrame();
			assert frame != null;

			// Render the effect for the face Rendering the effect involves these steps:
			// 1.Create the Sceneform face node.
			// 2.Add the face node to the Sceneform scene.
			// 3.Set the face region Renderable. Extracting the face mesh and
			// rendering the face effect is added to a listener on
			// the scene that gets called on every processed camera frame.
			Collection<AugmentedFace> augmentedFaces = frame.getUpdatedTrackables(AugmentedFace.class);

			// Make new AugmentedFaceNodes for any new faces.
			for (AugmentedFace augmentedFace : augmentedFaces) {
				if (isAdded) return;

				AugmentedFaceNode augmentedFaceMode = new AugmentedFaceNode(augmentedFace);
				augmentedFaceMode.setParent(customArFragment.getArSceneView().getScene());
				augmentedFaceMode.setFaceRegionsRenderable(modelRenderable);
				augmentedFaceMode.setFaceMeshTexture(texture);
				faceNodeMap.put(augmentedFace, augmentedFaceMode);
				isAdded = true;

				// Remove any AugmentedFaceNodes associated with 
				// an AugmentedFace that stopped tracking.
				Iterator<Map.Entry<AugmentedFace, AugmentedFaceNode>> iterator = faceNodeMap.entrySet().iterator();
				Map.Entry<AugmentedFace, AugmentedFaceNode> entry = iterator.next();
				AugmentedFace face = entry.getKey();
				while (face.getTrackingState() == TrackingState.STOPPED) {
					AugmentedFaceNode node = entry.getValue();
					node.setParent(null);
					iterator.remove();
				}
			}
		});
	}
}
